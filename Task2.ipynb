{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Task2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPhpNfJZVHtDHzI4cyJZJqb",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siposroland/cvs_hw_3d/blob/master/Task2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VfSUik9S_KMJ",
        "colab_type": "text"
      },
      "source": [
        "# Download model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HGC7V1r-2Mm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://github.com/siposroland/cvs_hw_3d/raw/master/model.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VEbI0b34_Y_D",
        "colab_type": "text"
      },
      "source": [
        "# Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ-6eZqp_qKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import optim\n",
        "\n",
        "# Convolutional module (Conv+ReLU+BatchNorm)\n",
        "class Conv(nn.Module):\n",
        "  def __init__(self, in_channels, channels,kernel_size=3, stride=1):   #kernel_size=3\n",
        "     super(Conv, self).__init__()\n",
        "     self.conv = nn.Conv2d(in_channels, channels, kernel_size, stride=stride, padding=kernel_size//2, bias=False)   #padding=1\n",
        "     self.bn = nn.BatchNorm2d(channels)\n",
        "  def forward(self,x):\n",
        "     return self.bn(torch.relu(self.conv(x)))\n",
        "  \n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, base_channels=16, in_channels=3, num_classes=55):  #in_channels=4\n",
        "      super(ConvNet, self).__init__()   \n",
        "      \n",
        "      self.c11 = Conv(in_channels, base_channels)\n",
        "      self.c12 = Conv(base_channels, base_channels)\n",
        "      self.d1 = Conv(base_channels, base_channels*2, stride=2)\n",
        "\n",
        "      self.c21 = Conv(base_channels*2, base_channels*2)\n",
        "      self.c22 = Conv(base_channels*2, base_channels*2)\n",
        "      self.d2 = Conv(base_channels*2, base_channels*4, stride=2)\n",
        "        \n",
        "      self.c31 = Conv(base_channels*4, base_channels*4)\n",
        "      self.c32 = Conv(base_channels*4, base_channels*4)\n",
        "      self.d3 = Conv(base_channels*4, base_channels*8, stride=2)\n",
        "        \n",
        "      self.c41 = Conv(base_channels*8, base_channels*8)\n",
        "      self.c42 = Conv(base_channels*8, base_channels*8)\n",
        "      self.d4 = Conv(base_channels*8, base_channels*16, stride=2)\n",
        "        \n",
        "      self.c51 = Conv(base_channels*16, base_channels*16)\n",
        "      self.c52 = Conv(base_channels*16, base_channels*16)\n",
        "      self.d5 = Conv(base_channels*16, base_channels*32, stride=2)\n",
        "      # Input image is 32x32 -> after 5 downscaling the activation map is 1x1\n",
        "      \n",
        "      # Classifier is a convolution that produces num_classes class scores\n",
        "      self.classifier = nn.Conv2d(base_channels*32,num_classes, 1) #kernel_size=1\n",
        "\n",
        "  def forward(self,x):\n",
        "        # Class all the layers\n",
        "        x = self.d1(self.c12(self.c11(x)))\n",
        "        x = self.d2(self.c22(self.c21(x)))\n",
        "        x = self.d3(self.c32(self.c31(x)))\n",
        "        x = self.d4(self.c42(self.c41(x)))\n",
        "        x = self.d5(self.c52(self.c51(x)))\n",
        "        return torch.squeeze(self.classifier(x))\n",
        "\n",
        "\n",
        "haveCuda = torch.cuda.is_available()\n",
        "\n",
        "#DATA AUGMENTATION\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),\n",
        "                         (0.24703233, 0.24348505, 0.26158768))\n",
        "     #transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629)) # mean = 0 and standard-deviation = 1\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32,padding=4),\n",
        "    # Random perturbance of brightness, contrast and color\n",
        "    transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.3,hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),\n",
        "                         (0.24703233, 0.24348505, 0.26158768))\n",
        "    #transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629)) # mean = 0 and standard-deviation = 1\n",
        "])\n",
        "\n",
        "#DATASETS\n",
        "#trainSet = torchvision.datasets.ImageFolder(root=\"/content/trafficSignsHW/trainFULL\", transform=transform)\n",
        "#testSet = torchvision.datasets.ImageFolder(root=\"/content/trafficSignsHW/testFULL\", transform=transform_val) #is_valid_file=None\n",
        "\n",
        "#trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=32, shuffle=True) #sampler overfitting kev√©s adatra bs=128\n",
        "#testLoader = torch.utils.data.DataLoader(testSet, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "def createNet():\n",
        "    net = ConvNet()\n",
        "    if haveCuda:\n",
        "        net = net.cuda()\n",
        "    return net\n",
        "\n",
        "def createLoss():\n",
        "    return nn.CrossEntropyLoss()\n",
        "\n",
        "# create optimizer\n",
        "def createOptimizer():\n",
        "    return optim.SGD(net.parameters(), lr=1e-2, momentum=0.5)  # lr=1e-1, momentum=0.9,nesterov=True, weight_decay=1e-4\n",
        "\n",
        "numEpoch =20\n",
        "\n",
        "def createScheduler():\n",
        "    return optim.lr_scheduler.CosineAnnealingLR(optimizer,numEpoch,eta_min=1e-2)\n",
        "\n",
        "\n",
        "#Progress bar\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "    # variables for loss\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "\n",
        "    # set the network to train (for batchnorm and dropout)\n",
        "    net.train()\n",
        "\n",
        "    # Create progress bar\n",
        "    bar = display(progress(0, len(trainLoader)), display_id=True)\n",
        "\n",
        "    for i, data in enumerate(trainLoader, 0):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        if haveCuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs = net(inputs)\n",
        "        # Loss\n",
        "        loss = criterion(outputs, labels)  #loss = torch.nn.functional.nll_loss(outputs, labels)\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # Gradient method\n",
        "        optimizer.step()\n",
        "\n",
        "        # Do not include these steps in the computational graph\n",
        "        with torch.no_grad():\n",
        "            # Accumulate loss\n",
        "            running_loss += loss.item()\n",
        "            # Get indices of the largest goodness values\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Count how many of the predictions equal the labels\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            # Accumulate number of total images seen\n",
        "            total += labels.shape[0]   ####\n",
        "\n",
        "        # Progress bar\n",
        "        bar.update(progress(i+1, len(trainLoader)))\n",
        "\n",
        "    # return loss and accuracy\n",
        "    tr_loss = running_loss / i\n",
        "    tr_corr = correct / total * 100\n",
        "    print(\"Train epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, tr_corr))\n",
        "    return tr_loss,tr_corr\n",
        "\n",
        "# Function for validating a single epch\n",
        "def val(epoch):\n",
        "\n",
        "    # variables for loss\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "\n",
        "    # set the network to eval  (for batchnorm and dropout)\n",
        "    net.eval()\n",
        "\n",
        "    # Create progress bar\n",
        "    bar = display(progress(0, len(testLoader)), display_id=True)\n",
        "\n",
        "    for i, data in enumerate(testLoader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        if haveCuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Do not include these steps in the computational graph\n",
        "        with torch.no_grad():\n",
        "            # Forward\n",
        "            outputs = net(inputs)\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Compute statistics, just like before\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.shape[0]\n",
        "\n",
        "        bar.update(progress(i+1, len(testLoader)))\n",
        "\n",
        "    # return loss and accuracy\n",
        "    val_loss = running_loss / i\n",
        "    val_corr = correct / total * 100\n",
        "    print(\"Test epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, val_corr))\n",
        "    return val_loss,val_corr\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vTKNYEnsJnEC",
        "colab_type": "text"
      },
      "source": [
        "# classifying image"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GyEGUdma_vAL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "transform = transforms.Compose([transforms.ToTensor()]) \n",
        "\n",
        "#Read model\n",
        "model = torch.load(\"./model.pth\")\n",
        "model.eval()\n",
        "\n",
        "def prepend(list, str): \n",
        "    list = [str + i for i in list] \n",
        "    return(list) \n",
        "\n",
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(l, key = alphanum_key)\n",
        "\n",
        "def hf_DL_task(path_of_source_pickle,path_of_destination_pickle):\n",
        "  # Define used arrays and variables\n",
        "  namesRGB = []\n",
        "\n",
        "  # Get folders\n",
        "  myFolderList = sorted([f.path for f in os.scandir(\"/content/HW\") if f.is_dir()])\n",
        "\n",
        "  # Put all RGB images to an array from \"gx\" folders\n",
        "  for element in myFolderList:\n",
        "    \n",
        "    # Get and sort list of objects\n",
        "    actualRGB = (sorted_nicely(glob.glob1(element + \"/rgb\", \"*.jpg\")))\n",
        "    \n",
        "    # Add path to all images\n",
        "    path = element.replace('/content/', '')\n",
        "    actualRGB = prepend(actualRGB, path + '/rgb/')\n",
        "    \n",
        "    \n",
        "    # Put names to the big global array\n",
        "    namesRGB = namesRGB + actualRGB\n",
        "  \n",
        "  # Open source pickle what contains data from previous tasks\n",
        "  file = open(path_of_source_pickle,'rb')\n",
        "  ourPrediction = pickle.load(file)\n",
        "  \n",
        "  # Loop throught all images\n",
        "  for photoIndex in range(len(namesRGB)):\n",
        "    # Get the name of the actual RGB picture\n",
        "    actualPic = namesRGB[photoIndex]\n",
        "\n",
        "    for actObject in ourPrediction[actualPic][\"objects\"]:\n",
        "      # Get center coordinates of the object's bounding box\n",
        "      u = actObject[0]\n",
        "      v = actObject[1]\n",
        "      w = actObject[2]\n",
        "      h = actObject[3]\n",
        "      c = actObject[4]\n",
        "      \n",
        "      #if Class  name== 'traffic sign'\n",
        "      if c==0:\n",
        "        crop_image = actualPic[v-w//2:v+w//2, u-h//2:u+h//2]\n",
        "        rs_img=cv2.resize(crop_image, (32,32), interpolation = cv2.INTER_AREA)\n",
        "        rs_img_rgb= cv2.cvtColor(rs_img,cv2.COLOR_BGR2RGB)\n",
        "        dl_img = transform(rs_img_rgb)  # Preprocess image\n",
        "        dl_img = dl_img.unsqueeze(0)  # Add batch dimension\n",
        "        if haveCuda:\n",
        "          dl_img=dl_img.cuda()\n",
        "        output = model(dl_img)  # Forward pass\n",
        "        _, pred = torch.max(output, 0)  # Get predicted class\n",
        "        \n",
        "        #Put subclassName to our prediction\n",
        "        actObject[5] = pred.item()\n",
        "  \n",
        "  # Save results to our predictions\n",
        "  pickle.dump(ourPrediction, open(path_of_destination_pickle, 'wb'))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}