{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of HF_3d_task_1_fgv.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/siposroland/cvs_hw_3d/blob/master/HF_merge_all_tasks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ul0rvDQ2ZtmZ",
        "colab_type": "text"
      },
      "source": [
        "# **Computer Vision Systems Homework**\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5PuwE234Sfh7",
        "colab_type": "text"
      },
      "source": [
        "# **Readme**\n",
        "\n",
        " Please run all 3 sections:\n",
        "\n",
        "*   Download elements and model\n",
        "*   Run the sources\n",
        "*   Run Evalutation with 3 task functions\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fOTJfoULdtTy",
        "colab_type": "text"
      },
      "source": [
        "# Your Work"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t2UYHdpaSI_U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Homework dataset\n",
        "!wget http://deeplearning.iit.bme.hu/CVS/HW.zip\n",
        "!unzip -qq HW.zip\n",
        "!rm HW.zip\n",
        "\n",
        "# Traffic Sign Classification set\n",
        "!wget http://deeplearning.iit.bme.hu/CVS/trafficSignsHW.zip\n",
        "!unzip -qq trafficSignsHW.zip\n",
        "!rm trafficSignsHW.zip\n",
        "\n",
        "# Get model\n",
        "!wget https://github.com/siposroland/cvs_hw_3d/raw/master/model.pth"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkYdH3g5RYWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Task 1: (traditional vision)\n",
        "# BASIC: Create an algorithm to accurately detect and classify the 3 objects of interest (Cactus, Vehicle, Traffic Sign). You don't have to determine the subclass at this point.\n",
        "# OUTPUT: center, width, high and type of objects / pictures\n",
        "\n",
        "# HARDCORE: Determine the subclasses of Cacti and Vehicles\n",
        "# OUTPUT: center, width, high and type of objects + subclass of cacti and vehicles / pictures\n",
        "\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import argparse\n",
        "import time\n",
        "import os\n",
        "import math\n",
        "#from evaluate import evaluate\n",
        "\n",
        "font = cv2.FONT_HERSHEY_COMPLEX\n",
        "\n",
        "################################## different edge and contour detection\n",
        "def getBlurredEdges(img):\n",
        "  imgEq = cv2.equalizeHist(img)\n",
        "  imgBlur = cv2.GaussianBlur(imgEq, (5,5),1)\n",
        "  #kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])    #élesítés\n",
        "  #sharpenedImg = cv2.filter2D(imgBlur, -1, kernel)\n",
        "\n",
        "  imgCanny = cv2.Canny(imgBlur, 50, 100)\n",
        "  return imgCanny\n",
        "\n",
        "def getSimpleEdges(img):\n",
        "  imgCanny = cv2.Canny(img, 50, 100)\n",
        "  return imgCanny\n",
        "\n",
        "def getEqEdges(img):\n",
        "  imgEq = cv2.equalizeHist(img)\n",
        "  imgCanny = cv2.Canny(imgEq, 50, 100)\n",
        "  return imgCanny\n",
        "\n",
        "def getSharpenedEdges(img):\n",
        "  kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])    #élesítés\n",
        "  imgBlur = cv2.GaussianBlur(img, (5,5),1)\n",
        "  sharpenedImg = cv2.filter2D(imgBlur, -1, kernel)\n",
        "  imgCanny = cv2.Canny(sharpenedImg, 50, 100)\n",
        "  return imgCanny\n",
        "\n",
        "def getOnlySharpenedEdges(img):\n",
        "  imgEq = cv2.equalizeHist(img)\n",
        "  kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])    #élesítés\n",
        "  sharpenedImg = cv2.filter2D(imgEq, -1, kernel)\n",
        "  imgCanny = cv2.Canny(sharpenedImg, 100, 200)\n",
        "  return imgCanny\n",
        "\n",
        "def getOnlyBlurredEdges(img):\n",
        "  imgBlur = cv2.GaussianBlur(img, (5,5),1)\n",
        "  imgCanny = cv2.Canny(imgBlur, 50, 100)\n",
        "  return imgCanny\n",
        "\n",
        "def getContours(img):\n",
        "  imgGray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  blurredEdges = getBlurredEdges(imgGray)\n",
        "  contours=[]\n",
        "  blurredContours, _ = cv2.findContours(blurredEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "  contours.append(blurredContours)\n",
        "  simpleEdges = getSimpleEdges(imgGray)\n",
        "  simpleContours, _ = cv2.findContours(simpleEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "  contours.append(simpleContours)\n",
        "  eqEdges = getEqEdges(imgGray)\n",
        "  eqContours, _ = cv2.findContours(eqEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "  sharpenedEdges = getSharpenedEdges(imgGray)\n",
        "  sharpenedContours, _ = cv2.findContours(sharpenedEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "  contours.append(sharpenedContours)\n",
        "  onlyBlurredEdges = getOnlyBlurredEdges(imgGray)\n",
        "  onlyBlurredContours, _ = cv2.findContours(onlyBlurredEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "  contours.append(onlyBlurredContours)\n",
        "  #onlySharpenedEdges = getOnlySharpenedEdges(imgGray)\n",
        "  #onlySharpenedContours, _ = cv2.findContours(onlySharpenedEdges, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)\n",
        "  #contours.append(onlySharpenedContours)\n",
        "  print(\"contour test:\")\n",
        "  contoursAndRectangles = []\n",
        "  for contourGroup in contours:        #keresés az összes kontúr típusban\n",
        "    for i in range(len(contourGroup)):\n",
        "      cnt = contourGroup[i]\n",
        "      contourLength = cv2.arcLength(cnt, True)\n",
        "      contourArea = cv2.contourArea(cnt, False)\n",
        "      approx = cv2.approxPolyDP(cnt, 0.01*cv2.arcLength(cnt, True), True)\n",
        "      #x = approx.ravel()[0]\n",
        "      #y = approx.ravel()[1]\n",
        "      if(contourLength > 60 and len(approx)==3):\n",
        "        print(\"tri\")\n",
        "        #cv2.drawContours(full_img, [approx], 0, (0, 255, 0), 2)\n",
        "        #cv2.putText(full_img, \"Triangle\", (x, y), font, 1, (0))\n",
        "      elif(contourLength > 60 and len(approx)==4):\n",
        "        #x, y, w, h = cv2.boundingRect(i)\n",
        "        #contoursAndRectangles.append([x,y,w,h],[cnt])\n",
        "        print(\"rect\")\n",
        "        #cv2.drawContours(full_img, [approx], 0, (0, 255, 0), 2)\n",
        "        #cv2.putText(full_img, \"Rectangle\", (x, y), font, 1, (0))\n",
        "      elif(contourLength > 60 and  contourArea> (contourLength**2 / (4*3.14) *0.5) and len(approx)==5 ):\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        contoursAndRectangles.append([[x,y,w,h],[cnt],[approx], \"Pentagon\"])\n",
        "\n",
        "      elif(contourLength > 60 and  contourArea> (contourLength**2 / (4*3.14) *0.5) and 6<=len(approx)<15):\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        contoursAndRectangles.append([[x,y,w,h],[cnt],[approx], \"Ellipse\"])\n",
        "      elif(contourLength > 60 and  contourArea> (contourLength**2 / (4*3.14) *0.5)):\n",
        "        x, y, w, h = cv2.boundingRect(cnt)\n",
        "        contoursAndRectangles.append([[x,y,w,h],[cnt],[approx], \"Circle\"])\n",
        "\n",
        "  drawnContours = []\n",
        "\n",
        "\n",
        "  for i in range(len(contoursAndRectangles)):\n",
        "    checkIfLargerRect(contoursAndRectangles, i)\n",
        "\n",
        "\n",
        "  for i in range(len(contoursAndRectangles)):\n",
        "    if contoursAndRectangles[i][0] == [0, 0, 0, 0]: continue\n",
        "    drawnContours.append(contoursAndRectangles[i])\n",
        "    cv2.rectangle(img, (contoursAndRectangles[i][0][0], contoursAndRectangles[i][0][1]), \n",
        "    (contoursAndRectangles[i][0][0]+contoursAndRectangles[i][0][2], contoursAndRectangles[i][0][1]+contoursAndRectangles[i][0][3]), (0,255,0),1)\n",
        "    #cv2.drawContours(img, contoursAndRectangles[i][2], 0, (0, 255, 0), 2)\n",
        "    cv2.putText(img, contoursAndRectangles[i][3], (x, y), font, 1, (0))\n",
        "\n",
        "\n",
        "  return onlyBlurredEdges, contoursAndRectangles\n",
        "\n",
        "\n",
        "#a kisebb intersection-nel tér vissza\n",
        "def getIntersectionPercent(rect1, rect2):\n",
        "  if((rect1[2] * rect1[3]) == 0 or (rect2[2] * rect2[3]) == 0):\n",
        "    return 0\n",
        "  [x,y,w,h] = getIntersection(rect1, rect2)\n",
        "  percent1 = ((w*h) / (rect1[2] * rect1[3])) *100\n",
        "  percent2 = ((w*h) /(rect2[2] * rect2[3])) *100\n",
        "  if(percent1>percent2): \n",
        "    return percent2\n",
        "  else:\n",
        "    return percent1\n",
        "\n",
        "\n",
        "def getIntersection(rect1, rect2):\n",
        "  x = max(rect1[0], rect2[0])\n",
        "  y = max(rect1[1], rect2[1])\n",
        "  w = min(rect1[0]+rect1[2], rect2[0]+rect2[2])-x\n",
        "  h = min(rect1[1]+rect1[3], rect2[1]+rect2[3])-y\n",
        "  if w<0 or h<0: return (0,0,0,0)\n",
        "  return(x,y,w,h)\n",
        "\n",
        "\n",
        "#ellenőrzi, hogy van-e olyan négyzet, ami tartalmazza ezt a négyzetet\n",
        "#cél: a legnagyobb wrapper négyzet megtalálása\n",
        "def checkIfLargerRect(contourAndRectangleList, pos):\n",
        "  rectParams = contourAndRectangleList[pos][0]\n",
        "  retval = False\n",
        "  for i in range(len(contourAndRectangleList)):\n",
        "    if(i == pos) or (contourAndRectangleList[i][0] == [0, 0, 0, 0]): continue\n",
        "    if(contourAndRectangleList[i][0][0]==rectParams[0] and contourAndRectangleList[i][0][1]==rectParams[1] and \n",
        "      (contourAndRectangleList[i][0][0]+contourAndRectangleList[i][0][2]) ==(rectParams[0]+rectParams[2]) and\n",
        "      (contourAndRectangleList[i][0][1]+contourAndRectangleList[i][0][3]) ==(rectParams[1]+rectParams[3])):\n",
        "      contourAndRectangleList[i][0] = [0,0,0,0]\n",
        "      retval = False\n",
        "    elif(contourAndRectangleList[i][0][0]<=rectParams[0] and contourAndRectangleList[i][0][1]<=rectParams[1] and \n",
        "      (contourAndRectangleList[i][0][0]+contourAndRectangleList[i][0][2]) >=(rectParams[0]+rectParams[2]) and\n",
        "      (contourAndRectangleList[i][0][1]+contourAndRectangleList[i][0][3]) >=(rectParams[1]+rectParams[3])):\n",
        "      contourAndRectangleList[pos][0] = [0,0,0,0] \n",
        "      retval = True\n",
        "\n",
        "    elif(getIntersectionPercent(rectParams, [contourAndRectangleList[i][0][0], \n",
        "    contourAndRectangleList[i][0][1], contourAndRectangleList[i][0][2], contourAndRectangleList[i][0][3]]) > 80):  #overlapping négyzet eltávolítása, ha esetleg van\n",
        "      contourAndRectangleList[i][0] = [0,0,0,0] #másik négyzet eltávolítása\n",
        "      retval = False\n",
        "  return retval\n",
        "\n",
        "\n",
        "\n",
        "#transform color \n",
        "def colorTransform(img):\n",
        "  imgValMean = cv2.mean(img)\n",
        "\n",
        "  print(\"img color val means: \")\n",
        "  print(imgValMean)\n",
        "\n",
        "  millis = int(round(time.time() * 1000))\n",
        "  print(millis)\n",
        "  \n",
        "  image_data = np.asarray(img)\n",
        "  selectorCheck = np.zeros((480, 640))     #mutatja, hogy mi alapján végzek szín szűrést\n",
        "  greenInHighBlue = 0  #sok kéket tartalmazó színben szereplő zöld\n",
        "  redInHighBlue = 0    #sok kéket tartalmazó színben szereplő piros\n",
        "  blueInHighBlue = 0\n",
        "  highBluePixels = 0   #sok kéket tartalmazó pixelek száma\n",
        "  print(\"image data test:\")\n",
        "  print(len(image_data[0]))\n",
        "  for i in range(len(image_data)):\n",
        "    for j in range(len(image_data[0])):\n",
        "      pixel = image_data[i][j] \n",
        "      if(pixel[0]>imgValMean[0]*1.3 and pixel[2]>imgValMean[0]*0.5):\n",
        "        blueInHighBlue += pixel[0]\n",
        "        greenInHighBlue += pixel[1]\n",
        "        redInHighBlue += pixel[2]\n",
        "        highBluePixels += 1\n",
        "        selectorCheck[i][j] = 255\n",
        "  \n",
        "  greenInHighBlue = greenInHighBlue/highBluePixels\n",
        "  redInHighBlue = redInHighBlue/highBluePixels\n",
        "  blueInHighBlue = blueInHighBlue/highBluePixels\n",
        "\n",
        "  print(\"blue in high blue:\")\n",
        "  print(blueInHighBlue)\n",
        "  print(\"green in high blue:\")\n",
        "  print(greenInHighBlue)\n",
        "  print(\"red in high blue:\")\n",
        "  print(redInHighBlue)\n",
        "\n",
        "\n",
        "  multGreen = 200/greenInHighBlue\n",
        "  multRed = 150/redInHighBlue\n",
        "  multBlue = 150/blueInHighBlue\n",
        "\n",
        "\n",
        "  ##itt beállítom a képet, ezt nem feltétlenül fogom megtenni, az éles alaklmazásban csak a színkeresési feltételeket transzformálom, most viszont jól jön\n",
        "  for i in range(0,img.shape[0]):       #ez már nem annyira nagyonlassú\n",
        "    for j in range(0,img.shape[1]):\n",
        "      pixelBlue = img.item(i, j, 0)\n",
        "      pixelGreen = img.item(i, j, 1)\n",
        "      pixelRed = img.item(i, j, 2)\n",
        "      img.itemset((i, j, 1), min(pixelGreen*multGreen, 255))\n",
        "      img.itemset((i, j, 2), min(pixelRed*multRed, 255))\n",
        "      img.itemset((i, j, 0), min(pixelBlue*multBlue, 255))\n",
        "\n",
        "\n",
        "  millis = int(round(time.time() * 1000))\n",
        "  imgValMean = cv2.mean(img)\n",
        "  print(\"modified picture means: \")\n",
        "  print(imgValMean)\n",
        "\n",
        "  #cv2.imwrite( \"./modImg/img1.jpg\", img );\n",
        "  return img\n",
        "\n",
        "def getWhiteThings(baseImg): \n",
        "  ######## táblák és fejek\n",
        "  baseImg_hsv = cv2.cvtColor(baseImg, cv2.COLOR_BGR2HSV)\n",
        "  kernel = np.ones((5,5),np.uint8)\n",
        "  hsv_color1 = np.asarray([0, 0, 101])   \n",
        "  hsv_color2 = np.asarray([70, 137, 255])   \n",
        "\n",
        "  #hsv_color3 = \n",
        "\n",
        "  white_things = cv2.inRange(baseImg_hsv, hsv_color1, hsv_color2)\n",
        "\n",
        "\n",
        "  \n",
        "  w_t_opened = cv2.morphologyEx(white_things, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "  w_t_closed = cv2.morphologyEx(w_t_opened, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
        "\n",
        "  return white_things\n",
        "\n",
        "def getWhiteThings2(baseImg): \n",
        "  ######## táblák és fejek\n",
        "  baseImg_hsv = cv2.cvtColor(baseImg, cv2.COLOR_BGR2HSV)\n",
        "  kernel = np.ones((5,5),np.uint8)\n",
        "  hsv_color1 = np.asarray([0, 0, 101])   \n",
        "  hsv_color2 = np.asarray([255, 137, 255])   \n",
        "\n",
        "  #hsv_color3 = \n",
        "\n",
        "  white_things = cv2.inRange(baseImg_hsv, hsv_color1, hsv_color2)\n",
        "\n",
        "  w_t_opened = cv2.morphologyEx(white_things, cv2.MORPH_OPEN, kernel, iterations=1)\n",
        "  w_t_closed = cv2.morphologyEx(w_t_opened, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
        "\n",
        "  return white_things\n",
        "  \n",
        "\n",
        "\n",
        "def analyzeContours(contoursAndRectangles, whiteThings, baseImg):\n",
        "  things = np.zeros((480,640,1), np.uint8)\n",
        "  infos = np.zeros((480,640,1), np.uint8)\n",
        "  cactiRectangles = []\n",
        "  trafficSignRectangles = []\n",
        "  for i in contoursAndRectangles:\n",
        "    if(i[0] != [0, 0, 0, 0]):\n",
        "      contour = i[1]\n",
        "      thisThing = np.zeros((480,640,1), np.uint8)\n",
        "\n",
        "      cv2.drawContours(things, contour, 0, (255,255,255), -1)\n",
        "\n",
        "      cv2.drawContours(thisThing, contour, 0, (255,255,255), -1)\n",
        "      selectedThing = cv2.bitwise_and(whiteThings, whiteThings, mask = thisThing)\n",
        "      avg = cv2.mean(selectedThing, mask=thisThing)\n",
        "      if(avg[0] > 197):\n",
        "        #szóval ez egy kaktuszfej\n",
        "        x1, y1, x2, y2 = calculateCactiWrapper(i[0])\n",
        "        cactiRectangles.append({\n",
        "          \"cactiHead\": i[0],\n",
        "          \"cactiHeadContour\": contour,\n",
        "          \"cactiWrapper\": [x1,y1,x2,y2]\n",
        "        })\n",
        "        cv2.rectangle(baseImg, (x1, y1), (x2, y2), (0,0,255),1)\n",
        "      elif(avg[0] > 20):\n",
        "        #szóval ez egy tábla\n",
        "        x1 = i[0][0]\n",
        "        y1 = i[0][1]\n",
        "        x2 = i[0][0]+i[0][2]\n",
        "        y2 = i[0][1]+i[0][3]\n",
        "        trafficSignRectangles.append([x1, y1, x2, y2])\n",
        "        cv2.rectangle(baseImg, (x1, y1), (x2, y2), (255,0,0),1)\n",
        "      cv2.putText(infos, str(avg), (i[0][0], i[0][1]), font, 1, (255))    #i[0][0] és i[0][1] x és y\n",
        "\n",
        "  res = cv2.bitwise_and(whiteThings, whiteThings, mask = things)\n",
        "  return res, infos, cactiRectangles, trafficSignRectangles\n",
        "\n",
        "\n",
        "\n",
        "def calculateDistance(x1, y1, x2, y2):\n",
        "  return math.sqrt((x1-x2)**2+(y1-y2)**2)\n",
        "\n",
        "\n",
        "#a feladata, hogy a detektált objektumokat tovább szűrje, hogy a hibákat eltávolítsa\n",
        "def postProcessObjects(cactis, trafficSigns, vehicles):\n",
        "  print(\"asd\")\n",
        "\n",
        "  ###### kaktuszok átnézése, a kicsi fejek, és a hátoldali fej detektálás kiszűrése\n",
        "  smallHeadsRemoved = []\n",
        "\n",
        "  for i in cactis:\n",
        "    if(i[\"cactiHead\"][3]>20):\n",
        "      smallHeadsRemoved.append(i)\n",
        "\n",
        "  headsOnBackRemoved = []\n",
        "  if(len(smallHeadsRemoved) == 1):\n",
        "    headsOnBackRemoved.append(i)\n",
        "  else:\n",
        "    for i in smallHeadsRemoved:\n",
        "      isItAWrongHead = False\n",
        "      for j in smallHeadsRemoved:\n",
        "        distance = calculateDistance(i[\"cactiHead\"][0], i[\"cactiHead\"][1], j[\"cactiHead\"][0], j[\"cactiHead\"][1])\n",
        "        if(distance < 150):\n",
        "          area_i = i[\"cactiHead\"][2] * i[\"cactiHead\"][3]\n",
        "          area_j = j[\"cactiHead\"][2] * j[\"cactiHead\"][3]\n",
        "          if(area_i < area_j):  #ha ez feltételezhetően nem egy jó fej\n",
        "            isItAWrongHead = True\n",
        "      if(not isItAWrongHead):\n",
        "        headsOnBackRemoved.append(i)\n",
        "\n",
        "\n",
        "  ##összes suv, és összes plane kiválogatása\n",
        "  SUVs = []\n",
        "  planes = []\n",
        "  trucks = []\n",
        "\n",
        "  for i in vehicles:\n",
        "    if(i[\"type\"] == \"SUV\" or i[\"type\"] == \"plane\"): #meg kell nézni, hogy milyen közel van a kaktuszhoz, mivel lehet, hogy cserép\n",
        "      print(\"DISTANCE TEST:\")\n",
        "      isVehicle = True\n",
        "      for j in headsOnBackRemoved:\n",
        "        cactiHeadMid_x = j[\"cactiHead\"][0] + j[\"cactiHead\"][2]/2\n",
        "        cactiHeadMid_y = j[\"cactiHead\"][1] + j[\"cactiHead\"][3]/2\n",
        "        SUVMid_x = (i[\"rect\"][0] + i[\"rect\"][2]) / 2\n",
        "        SUVMid_y = (i[\"rect\"][1] + i[\"rect\"][3]) / 2\n",
        "        distance = calculateDistance(cactiHeadMid_x, cactiHeadMid_y, SUVMid_x, SUVMid_y)\n",
        "        print(distance)\n",
        "        if distance < 100:\n",
        "          isVehicle = False\n",
        "      if isVehicle:\n",
        "        if(i[\"type\"]== \"plane\"):\n",
        "          planes.append(i)\n",
        "        elif(i[\"type\"]== \"SUV\"):\n",
        "          SUVs.append(i)\n",
        "    elif(i[\"type\"] == \"truck\"):\n",
        "      trucks.append(i)\n",
        "    \n",
        "  if(len(SUVs)>1):\n",
        "    realSUV = {}\n",
        "    maxContourLength = 0\n",
        "    for i in SUVs:\n",
        "      if i[\"contourLength\"] > maxContourLength:\n",
        "        realSUV = i\n",
        "        maxContourLength = i[\"contourLength\"]\n",
        "    SUVs = []\n",
        "    SUVs.append(realSUV)\n",
        "  \n",
        "  if(len(trucks) > 1):\n",
        "    realTruck = {}\n",
        "    maxContourLength = 0\n",
        "    for i in trucks:\n",
        "      if i[\"contourLength\"] > maxContourLength:\n",
        "        realTruck = i\n",
        "        maxContourLength = i[\"contourLength\"]\n",
        "    trucks = []\n",
        "    trucks.append(realTruck)\n",
        "\n",
        "  #a darut ne érzékelje plane-nek\n",
        "  if(len(planes)>0):\n",
        "    newPlanes = []\n",
        "    for i in planes: \n",
        "      if(len(trucks) >0):\n",
        "        truckMid_x = (trucks[0][\"rect\"][0] + trucks[0][\"rect\"][2]) / 2\n",
        "        truckMid_y = (trucks[0][\"rect\"][1] + trucks[0][\"rect\"][3]) / 2\n",
        "        planeMid_x = (i[\"rect\"][0] +i[\"rect\"][2]) / 2\n",
        "        planeMid_y = (i[\"rect\"][1] + i[\"rect\"][3]) / 2\n",
        "        distance = calculateDistance(truckMid_x, truckMid_y, planeMid_x, planeMid_y)\n",
        "        if(distance<50):  #ha túl közel van, a truck-hoz, akkor ez egy daru, continue\n",
        "          continue\n",
        "      newPlanes.append(i)\n",
        "    planes = newPlanes\n",
        "  \n",
        "  if(len(planes) > 1):\n",
        "    realPlane = {}\n",
        "    maxContourLength = 0\n",
        "    for i in planes:\n",
        "      if i[\"contourLength\"] > maxContourLength:\n",
        "        realPlane = i\n",
        "        maxContourLength = i[\"contourLength\"]\n",
        "    planes = []\n",
        "    planes.append(realPlane)\n",
        "\n",
        "#################################### csak a wrapper visszaadása\n",
        "  newCactis = []\n",
        "  newVehicles = [] #egylőre teszt, itt majd benne lesz a típus is\n",
        "  for i in headsOnBackRemoved:\n",
        "    #newCactis.append(i[\"cactiWrapper\"])\n",
        "    newCactis.append(i)\n",
        "  for i in planes:\n",
        "    newVehicles.append({\n",
        "      \"type\": 2,\n",
        "      \"rect\":i[\"rect\"]\n",
        "    })\n",
        "  for i in SUVs:\n",
        "    newVehicles.append({\n",
        "      \"type\": 0,\n",
        "      \"rect\":i[\"rect\"]\n",
        "    })\n",
        "  for i in trucks:\n",
        "    newVehicles.append({\n",
        "      \"type\": 1,\n",
        "      \"rect\":i[\"rect\"]\n",
        "    })\n",
        "  return newCactis, trafficSigns, newVehicles\n",
        "\n",
        "\n",
        "def calculateCactiWrapper(cactiHeadWrapper):\n",
        "  x1 = max(cactiHeadWrapper[0] - 20, 0)\n",
        "  y1 = max(cactiHeadWrapper[1] - 20, 0)\n",
        "  x2 = min(cactiHeadWrapper[0]+cactiHeadWrapper[2] + 20, 640)\n",
        "  y2 = min(cactiHeadWrapper[1]+cactiHeadWrapper[3] + 100, 480)\n",
        "  return [x1, y1, x2, y2]\n",
        "\n",
        "def detectVehicles(img):\n",
        "  vehicleList = []\n",
        "  img_hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
        "  cv2.rectangle(img_hsv,(0,0),(640,160),(0,0,0),-1) #a felső 1/3 fekete\n",
        "  hsv_color1 = np.asarray([0, 155, 59])   \n",
        "  hsv_color2= np.asarray([10, 255, 255])   \n",
        "  plane = cv2.inRange(img_hsv, hsv_color1, hsv_color2)\n",
        "\n",
        "  _, th = cv2.threshold(plane, thresh=10, maxval=255, type=cv2.THRESH_BINARY)\n",
        "  kernel = np.ones((5,5),np.uint8)\n",
        "  th_opened = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "\n",
        "  contours, hierarchy = cv2.findContours(th_opened, 1, 2)\n",
        "  for cnt in contours:\n",
        "    contourLength = cv2.arcLength(cnt, True)\n",
        "    if contourLength>200:\n",
        "      contourArea = cv2.contourArea(cnt, False)\n",
        "      print(\">>> Vehicle contour test:\")\n",
        "      print(contourLength)\n",
        "      print(contourArea)\n",
        "      \n",
        "      areaPerLength = contourArea / contourLength\n",
        "      print(\"contour area per length \"+str(areaPerLength))\n",
        "      x,y,w,h = cv2.boundingRect(cnt)\n",
        "      boundingRectArea = w*h\n",
        "      areaPerBoundingRectArea = contourArea / boundingRectArea\n",
        "      print(\"areaPerBoundingRectArea\"+str(areaPerBoundingRectArea))\n",
        "      if(areaPerLength >7.5 and areaPerBoundingRectArea > 0.48 and contourArea>2500):  #! ez egy SUV\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "        vehicleList.append({\n",
        "          \"contourLength\" : contourLength,\n",
        "          \"type\": \"SUV\",\n",
        "          \"rect\":[x,y,x+w,y+h]\n",
        "        })\n",
        "        text = \"SUV\" + str(areaPerLength)\n",
        "        cv2.putText(img, text, (x, y), font, 1, (0,0,255))\n",
        "      elif (areaPerLength>6 and areaPerBoundingRectArea < 0.48): #!ez egy plane\n",
        "        cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "        vehicleList.append({\n",
        "          \"contourLength\" : contourLength,\n",
        "          \"type\": \"plane\",\n",
        "          \"rect\":[x,y,x+w,y+h]\n",
        "        })\n",
        "        text = \"Plane\" + str(areaPerLength)\n",
        "        cv2.putText(img, text, (x, y), font, 1, (0,0,255))\n",
        "      else:\n",
        "        text = str(areaPerLength) \n",
        "        cv2.putText(img, text, (x, y), font, 1, (0,0,255))\n",
        "      cv2.drawContours(img, [cnt], 0, (0,255,0), 2)\n",
        "\n",
        "  \n",
        "  hsv_color1 = np.asarray([13, 183, 134])   \n",
        "  hsv_color2= np.asarray([29, 255, 255])   \n",
        "  truck = cv2.inRange(img_hsv, hsv_color1, hsv_color2)\n",
        "  \n",
        "  _, th = cv2.threshold(truck, thresh=10, maxval=255, type=cv2.THRESH_BINARY)\n",
        "  kernel = np.ones((5,5),np.uint8)\n",
        "  th_opened = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
        "  contours, hierarchy = cv2.findContours(th_opened, 1, 2) \n",
        "\n",
        "  for cnt in contours:\n",
        "    contourLength = cv2.arcLength(cnt, True) \n",
        "    contourArea = cv2.contourArea(cnt, False) \n",
        "    if contourLength>200 and contourArea>1500 and contourArea<6000: #legyen kisebb mint 6k?\n",
        "      print(\"truck contour area:\")\n",
        "      print(contourArea)\n",
        "      x,y,w,h = cv2.boundingRect(cnt)\n",
        "      cv2.rectangle(img,(x,y),(x+w,y+h),(0,0,255),2)\n",
        "      vehicleList.append({\n",
        "        \"contourLength\" : contourLength,\n",
        "        \"type\": \"truck\",\n",
        "        \"rect\":[x,y,x+w,y+h]\n",
        "      })\n",
        "      cv2.putText(img, \"Truck\", (x, y), font, 1, (0,0,255))\n",
        "  return th_opened, vehicleList\n",
        "\n",
        "\n",
        "\n",
        "def getClosedArcLength(curve): \n",
        "  return cv2.arcLength(curve, True)\n",
        "\n",
        "def isContainsPoint(point_x, point_y, rect):\n",
        "  if (point_x >= rect[0] and point_x <= (rect[0]+rect[2])) and (point_y >= rect[1] and point_y <=rect[1]+rect[3]):\n",
        "    print(\"_________found a collision:\")\n",
        "    print(\"this contains: \")\n",
        "    print(rect)\n",
        "    print(\"this point:\")\n",
        "    print([point_x , point_y])\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "def analyzeFaces(cactis, faceImg):\n",
        "  allFaces = np.zeros((480,640,1), np.uint8)\n",
        "  grayImg = cv2.cvtColor(faceImg, cv2.COLOR_BGR2GRAY)\n",
        "  newCactis = []    #ebben benne lesz a típus is\n",
        "  for cacti in cactis:\n",
        "    faceMask = np.zeros((480,640,1), np.uint8)\n",
        "    cv2.drawContours(faceMask, cacti[\"cactiHeadContour\"], 0, (255,255,255), -1)\n",
        "    #esetleg hist eq\n",
        "    #itt még a feldolgozást ki kell találni\n",
        "    avg = cv2.mean(grayImg, mask=faceMask)\n",
        "    thresholdVal = avg[0]*0.9 #ki kell találni, hogy mi legyen\n",
        "    selectedFace = cv2.bitwise_and(grayImg, grayImg, mask = faceMask)\n",
        "    #cv2.equalizeHist(img)\n",
        "    kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])    #élesítés\n",
        "    sharpenedFace = cv2.filter2D(selectedFace, -1, kernel)\n",
        "\n",
        "    _, th = cv2.threshold(sharpenedFace, thresh=thresholdVal, maxval=255, type=cv2.THRESH_BINARY)\n",
        "\n",
        "    th_inv = 255 - th\n",
        "    #kernel = np.ones((3,3),np.uint8)\n",
        "    #th_closed = cv2.morphologyEx(th, cv2.MORPH_CLOSE, kernel, iterations=1)\n",
        "    #inv_th = 255 - th\n",
        "    #blur = cv2.medianBlur(inv_th, 3)\n",
        "    #th = 255-blur\n",
        "\n",
        "    cnt, hierarchy = cv2.findContours(th_inv, 1 ,2)\n",
        "    sortedContours = sorted(cnt, key = lambda x:cv2.arcLength(x, True))\n",
        "    contourToShow = sortedContours[-1]\n",
        "    #cv2.drawContours(faceImg, [contourToShow], 0, (255, 0, 0), 1)\n",
        "    maskedMouthTest = np.zeros((480,640,1), np.uint8)\n",
        "    isSmile = False\n",
        "    for i in reversed(sortedContours):  #cél, hogy megtalálja a szájat\n",
        "      contourLength = cv2.arcLength(i, True)\n",
        "      contourArea = cv2.contourArea(i, False)\n",
        "      if(contourLength > 40 and contourArea<150 and contourLength<150):   #a száj megkeresése, ez többnyire jó\n",
        "        cv2.drawContours(faceImg, [i], 0, (255, 0, 0), 1)\n",
        "        print(\"contour length:\")\n",
        "        print(contourLength)\n",
        "        print(\"contour area:\")\n",
        "        print(contourArea)\n",
        "        x, y, w, h = cv2.boundingRect(i)\n",
        "        ##! tesztelni kell, hogy mit tekint mouth-nak\n",
        "        test_mask = np.zeros((480,640,1), np.uint8)\n",
        "        cv2.rectangle(test_mask, (x,y), (x+w, y+h), (255, 255, 255), -1)\n",
        "        maskedMouthTest = cv2.bitwise_and(th, th, mask=test_mask)\n",
        "\n",
        "        mouth = th[y:y+h, x:x+w]\n",
        "        if(w>15 and h>=5):\n",
        "          subArray1 = mouth[0:5, 0:5]\n",
        "          subArray2 = mouth[0:5, w-5:w]\n",
        "          unique, counts = np.unique(subArray1, return_counts=True)\n",
        "          for index, val in enumerate(unique):\n",
        "            if(val == 0):\n",
        "              if(counts[index] > 5):\n",
        "                print(\"count index test:\")\n",
        "                print(counts[index])\n",
        "                isSmile = True\n",
        "          unique, counts = np.unique(subArray2, return_counts=True)\n",
        "          for index, val in enumerate(unique):\n",
        "            if(val == 0):\n",
        "              if(counts[index] > 5):\n",
        "                print(\"count index test:\")\n",
        "                print(counts[index])\n",
        "                isSmile = True\n",
        "        break\n",
        "      else:   #ha nem talált szájat (ilyenkor van, hogy beleér az aljába, tehát sad)\n",
        "        isSmile = False\n",
        "    \n",
        "    print(\"is smile?\")\n",
        "    print(isSmile)\n",
        "    allFaces = cv2.bitwise_or(allFaces, th)\n",
        "\n",
        "    #TODO szemöldök detektálás\n",
        "    faceFeatureWrappers = []\n",
        "    isIntersectDetected = False\n",
        "    for i in sortedContours:\n",
        "      if(cv2.arcLength(i, True)>6 and cv2.arcLength(i, True)<40): \n",
        "        x, y, w, h = cv2.boundingRect(i)\n",
        "        faceFeatureWrappers.append([x,y,w,h])\n",
        "    for i in range(len(faceFeatureWrappers)):     #megnézi, hogy az i négyzetben benne van-e a j négyzet valamelyik sarka\n",
        "      if isIntersectDetected: break\n",
        "      for j in range (len(faceFeatureWrappers)):\n",
        "        if(i == j): continue\n",
        "        if isIntersectDetected: break \n",
        "        p = faceFeatureWrappers[j]\n",
        "        points = [[p[0], p[1]], [p[0]+p[2], p[1]], [p[0]+p[2], p[1]+p[3]], [p[0], p[1]+p[3]]]\n",
        "        for k in points:\n",
        "          if isContainsPoint(k[0], k[1], faceFeatureWrappers[i]):\n",
        "            isIntersectDetected = True\n",
        "            break\n",
        "        #if(isContainsPoint)\n",
        "        #print(i & j)\n",
        "    print(\"has eyebrows? : \")\n",
        "    print(isIntersectDetected)\n",
        "\n",
        "    ##################################### kiértékelés\n",
        "    cactiType = 0\n",
        "    if(isSmile and isIntersectDetected):\n",
        "      print(\"It is evil\")\n",
        "      cactiType = 3\n",
        "    elif(isSmile and not isIntersectDetected):\n",
        "      print(\"It is happy :)\")\n",
        "      cactiType = 0\n",
        "    elif(not isSmile and not isIntersectDetected):\n",
        "      print(\"It is sad :(\")\n",
        "      cactiType = 1\n",
        "    elif(not isSmile and isIntersectDetected):\n",
        "      print(\"It is angry\")\n",
        "      cactiType = 2\n",
        "\n",
        "    newCacti = cacti\n",
        "    cacti[\"type\"] = cactiType\n",
        "    newCactis.append(cacti)\n",
        "\n",
        "  #kaktusz for ciklus vége\n",
        "  #faceImg = cv2.bitwise_and(faceImg, faceImg, mask = faceMask)\n",
        "  return newCactis, allFaces\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def createMyAnswers():\n",
        "  myAnswers = {}\n",
        "  for subdir, dirs,  files in os.walk(\"./HW\"):\n",
        "    for file in files:\n",
        "      filepath = subdir + os.sep + file\n",
        "      if(subdir[-3:] == \"rgb\"):\n",
        "        print(\"dir test:\")\n",
        "        print(subdir[-6:-4])\n",
        "        baseImg = cv2.imread(filepath)\n",
        "        baseImgCpy = baseImg.copy()\n",
        "        baseImgCpy2 = baseImg.copy()\n",
        "        cactiFaceImg = baseImg.copy()\n",
        "        objectContours, contoursAndRectangles = getContours(baseImg)\n",
        "        #modColor = colorTransform(baseImgCpy)\n",
        "        whiteThings = getWhiteThings2(baseImgCpy)\n",
        "        res, infos, cactis, trafficSigns = analyzeContours(contoursAndRectangles, whiteThings, baseImgCpy)\n",
        "        test, vehicles = detectVehicles(baseImgCpy2)\n",
        "\n",
        "\n",
        "        cactis, trafficSigns, vehicles = postProcessObjects(cactis, trafficSigns, vehicles)\n",
        "        cactis, _ = analyzeFaces(cactis, cactiFaceImg)\n",
        "        \n",
        "        myObjects = []\n",
        "        for i in cactis:\n",
        "          u = (i[\"cactiWrapper\"][0]+i[\"cactiWrapper\"][2])//2\n",
        "          v = (i[\"cactiWrapper\"][1]+i[\"cactiWrapper\"][3])//2\n",
        "          w = i[\"cactiWrapper\"][2] - i[\"cactiWrapper\"][0]\n",
        "          h = i[\"cactiWrapper\"][3] - i[\"cactiWrapper\"][1] \n",
        "          myObject = [u, v, w, h, 2, i[\"type\"], 0, 0, 0]\n",
        "          myObjects.append(myObject)\n",
        "\n",
        "        for i in trafficSigns:\n",
        "          u = (i[0]+i[2])//2\n",
        "          v = (i[1]+i[3])//2\n",
        "          w = i[2] - i[0]\n",
        "          h = i[3] - i[1] \n",
        "          myObject = [u, v, w, h, 0, 0, 0, 0, 0]\n",
        "          myObjects.append(myObject)\n",
        "\n",
        "        for i in vehicles:\n",
        "          u = (i[\"rect\"][0]+i[\"rect\"][2])//2\n",
        "          v = (i[\"rect\"][1]+i[\"rect\"][3])//2\n",
        "          w = i[\"rect\"][2] - i[\"rect\"][0]\n",
        "          h = i[\"rect\"][3] - i[\"rect\"][1] \n",
        "          myObject = [u, v, w, h, 1, i[\"type\"], 0, 0, 0]\n",
        "          myObjects.append(myObject)\n",
        "\n",
        "        pose = [[1, 0, 0, 0],\n",
        "        [0, 1, 0, 0],\n",
        "        [0, 0, 1, 0],\n",
        "        [0, 0, 0, 1]]  \n",
        "        myPred = {\n",
        "           'poses' :[1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
        "           'objects' : myObjects\n",
        "        }\n",
        "        myAnswers['HW/'+subdir[-6:-4]+'/rgb/'+file]  = myPred\n",
        "  return myAnswers\n",
        "\n",
        "\n",
        "\n",
        "#################################################### MAIN ####################################################\n",
        "#testOnSingleImg()\n",
        "\n",
        "###### Answer and evaluation ######\n",
        "#myAnswers = createMyAnswers()\n",
        "#print(\"task 1 finished\")\n",
        "#rint(myAnswers)\n",
        "#evaluate(myAnswers)\n",
        "#pickle.dump(myAnswers, open('HW/ourpredictions.pickle', 'wb'))   \n",
        "\n",
        "#filehandler = open(b\"my_answer.pickle\",\"wb\")\n",
        "#pickle.dump(myAnswers,filehandler)\n",
        "\n",
        "# Task 2: (deep learning)\n",
        "# BASIC: Use a deep learning algorithm to classify traffic signs. The package provided includes a training and validation database of 32x32 RGB images.\n",
        "# OUTPUT: traffic signs / pictures (without 3 missing)\n",
        "\n",
        "# HARDCORE: Of the 55 possible traffic signs, 3 are missing from the training and test datasets. ('X - Priority', 'X - Turn left', 'X - Turn right') \n",
        "# As a result, the neural net trained in task 2 will not be able to classify them properly. Extend your neural network to classify these as well.\n",
        "# OUTPUT: traffic signs / pictures (all)\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torch import optim\n",
        "\n",
        "# Convolutional module (Conv+ReLU+BatchNorm)\n",
        "class Conv(nn.Module):\n",
        "  def __init__(self, in_channels, channels,kernel_size=3, stride=1):   #kernel_size=3\n",
        "     super(Conv, self).__init__()\n",
        "     self.conv = nn.Conv2d(in_channels, channels, kernel_size, stride=stride, padding=kernel_size//2, bias=False)   #padding=1\n",
        "     self.bn = nn.BatchNorm2d(channels)\n",
        "  def forward(self,x):\n",
        "     return self.bn(torch.relu(self.conv(x)))\n",
        "  \n",
        "\n",
        "class ConvNet(nn.Module):\n",
        "  def __init__(self, base_channels=16, in_channels=3, num_classes=55):  #in_channels=4\n",
        "      super(ConvNet, self).__init__()   \n",
        "      \n",
        "      self.c11 = Conv(in_channels, base_channels)\n",
        "      self.c12 = Conv(base_channels, base_channels)\n",
        "      self.d1 = Conv(base_channels, base_channels*2, stride=2)\n",
        "\n",
        "      self.c21 = Conv(base_channels*2, base_channels*2)\n",
        "      self.c22 = Conv(base_channels*2, base_channels*2)\n",
        "      self.d2 = Conv(base_channels*2, base_channels*4, stride=2)\n",
        "        \n",
        "      self.c31 = Conv(base_channels*4, base_channels*4)\n",
        "      self.c32 = Conv(base_channels*4, base_channels*4)\n",
        "      self.d3 = Conv(base_channels*4, base_channels*8, stride=2)\n",
        "        \n",
        "      self.c41 = Conv(base_channels*8, base_channels*8)\n",
        "      self.c42 = Conv(base_channels*8, base_channels*8)\n",
        "      self.d4 = Conv(base_channels*8, base_channels*16, stride=2)\n",
        "        \n",
        "      self.c51 = Conv(base_channels*16, base_channels*16)\n",
        "      self.c52 = Conv(base_channels*16, base_channels*16)\n",
        "      self.d5 = Conv(base_channels*16, base_channels*32, stride=2)\n",
        "      # Input image is 32x32 -> after 5 downscaling the activation map is 1x1\n",
        "      \n",
        "      # Classifier is a convolution that produces num_classes class scores\n",
        "      self.classifier = nn.Conv2d(base_channels*32,num_classes, 1) #kernel_size=1\n",
        "\n",
        "  def forward(self,x):\n",
        "        # Class all the layers\n",
        "        x = self.d1(self.c12(self.c11(x)))\n",
        "        x = self.d2(self.c22(self.c21(x)))\n",
        "        x = self.d3(self.c32(self.c31(x)))\n",
        "        x = self.d4(self.c42(self.c41(x)))\n",
        "        x = self.d5(self.c52(self.c51(x)))\n",
        "        return torch.squeeze(self.classifier(x))\n",
        "\n",
        "\n",
        "haveCuda = torch.cuda.is_available()\n",
        "\n",
        "#DATA AUGMENTATION\n",
        "transform_val = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),\n",
        "                         (0.24703233, 0.24348505, 0.26158768))\n",
        "     #transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629)) # mean = 0 and standard-deviation = 1\n",
        "])\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomCrop(32,padding=4),\n",
        "    # Random perturbance of brightness, contrast and color\n",
        "    transforms.ColorJitter(brightness=0.3,contrast=0.3,saturation=0.3,hue=0.2),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.49139968, 0.48215827, 0.44653124),\n",
        "                         (0.24703233, 0.24348505, 0.26158768))\n",
        "    #transforms.Normalize((0.3337, 0.3064, 0.3171), ( 0.2672, 0.2564, 0.2629)) # mean = 0 and standard-deviation = 1\n",
        "])\n",
        "\n",
        "#DATASETS\n",
        "#trainSet = torchvision.datasets.ImageFolder(root=\"/content/trafficSignsHW/trainFULL\", transform=transform)\n",
        "#testSet = torchvision.datasets.ImageFolder(root=\"/content/trafficSignsHW/testFULL\", transform=transform_val) #is_valid_file=None\n",
        "\n",
        "#trainLoader = torch.utils.data.DataLoader(trainSet, batch_size=32, shuffle=True) #sampler overfitting kevés adatra bs=128\n",
        "#testLoader = torch.utils.data.DataLoader(testSet, batch_size=32, shuffle=False)\n",
        "\n",
        "\n",
        "def createNet():\n",
        "    net = ConvNet()\n",
        "    if haveCuda:\n",
        "        net = net.cuda()\n",
        "    return net\n",
        "\n",
        "def createLoss():\n",
        "    return nn.CrossEntropyLoss()\n",
        "\n",
        "# create optimizer\n",
        "def createOptimizer():\n",
        "    return optim.SGD(net.parameters(), lr=1e-2, momentum=0.5)  # lr=1e-1, momentum=0.9,nesterov=True, weight_decay=1e-4\n",
        "\n",
        "numEpoch =20\n",
        "\n",
        "def createScheduler():\n",
        "    return optim.lr_scheduler.CosineAnnealingLR(optimizer,numEpoch,eta_min=1e-2)\n",
        "\n",
        "\n",
        "#Progress bar\n",
        "from IPython.display import HTML, display\n",
        "\n",
        "def progress(value, max=100):\n",
        "    return HTML(\"\"\"\n",
        "        <progress\n",
        "            value='{value}'\n",
        "            max='{max}',\n",
        "            style='width: 100%'\n",
        "        >\n",
        "            {value}\n",
        "        </progress>\n",
        "    \"\"\".format(value=value, max=max))\n",
        "\n",
        "\n",
        "\n",
        "def train(epoch):\n",
        "\n",
        "    # variables for loss\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "\n",
        "    # set the network to train (for batchnorm and dropout)\n",
        "    net.train()\n",
        "\n",
        "    # Create progress bar\n",
        "    bar = display(progress(0, len(trainLoader)), display_id=True)\n",
        "\n",
        "    for i, data in enumerate(trainLoader, 0):\n",
        "        \n",
        "        inputs, labels = data\n",
        "        if haveCuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        # Forward\n",
        "        outputs = net(inputs)\n",
        "        # Loss\n",
        "        loss = criterion(outputs, labels)  #loss = torch.nn.functional.nll_loss(outputs, labels)\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        # Gradient method\n",
        "        optimizer.step()\n",
        "\n",
        "        # Do not include these steps in the computational graph\n",
        "        with torch.no_grad():\n",
        "            # Accumulate loss\n",
        "            running_loss += loss.item()\n",
        "            # Get indices of the largest goodness values\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            # Count how many of the predictions equal the labels\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            # Accumulate number of total images seen\n",
        "            total += labels.shape[0]   ####\n",
        "\n",
        "        # Progress bar\n",
        "        bar.update(progress(i+1, len(trainLoader)))\n",
        "\n",
        "    # return loss and accuracy\n",
        "    tr_loss = running_loss / i\n",
        "    tr_corr = correct / total * 100\n",
        "    print(\"Train epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, tr_corr))\n",
        "    return tr_loss,tr_corr\n",
        "\n",
        "# Function for validating a single epch\n",
        "def val(epoch):\n",
        "\n",
        "    # variables for loss\n",
        "    running_loss = 0.0\n",
        "    correct = 0.0\n",
        "    total = 0\n",
        "\n",
        "    # set the network to eval  (for batchnorm and dropout)\n",
        "    net.eval()\n",
        "\n",
        "    # Create progress bar\n",
        "    bar = display(progress(0, len(testLoader)), display_id=True)\n",
        "\n",
        "    for i, data in enumerate(testLoader, 0):\n",
        "        # get the inputs\n",
        "        inputs, labels = data\n",
        "        if haveCuda:\n",
        "            inputs, labels = inputs.cuda(), labels.cuda()\n",
        "\n",
        "        # Do not include these steps in the computational graph\n",
        "        with torch.no_grad():\n",
        "            # Forward\n",
        "            outputs = net(inputs)\n",
        "            # Compute loss\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Compute statistics, just like before\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            total += labels.shape[0]\n",
        "\n",
        "        bar.update(progress(i+1, len(testLoader)))\n",
        "\n",
        "    # return loss and accuracy\n",
        "    val_loss = running_loss / i\n",
        "    val_corr = correct / total * 100\n",
        "    print(\"Test epoch %d loss: %.3f correct: %.2f\" % (epoch + 1, running_loss / i, val_corr))\n",
        "    return val_loss,val_corr\n",
        "\n",
        "transform = transforms.Compose([transforms.ToTensor()]) \n",
        "\n",
        "#Read model\n",
        "model = torch.load(\"./model.pth\", map_location=torch.device('cpu'))\n",
        "model.eval()\n",
        "\n",
        "def prepend(list, str): \n",
        "    list = [str + i for i in list] \n",
        "    return(list) \n",
        "\n",
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(l, key = alphanum_key)\n",
        "\n",
        "def hf_DL_task(path_of_source_pickle,path_of_destination_pickle):\n",
        "  # Define used arrays and variables\n",
        "  namesRGB = []\n",
        "\n",
        "  # Get folders\n",
        "  myFolderList = sorted([f.path for f in os.scandir(\"/content/HW\") if f.is_dir()])\n",
        "\n",
        "  # Put all RGB images to an array from \"gx\" folders\n",
        "  for element in myFolderList:\n",
        "    \n",
        "    # Get and sort list of objects\n",
        "    actualRGB = (sorted_nicely(glob.glob1(element + \"/rgb\", \"*.jpg\")))\n",
        "    \n",
        "    # Add path to all images\n",
        "    path = element.replace('/content/', '')\n",
        "    actualRGB = prepend(actualRGB, path + '/rgb/')\n",
        "    \n",
        "    \n",
        "    # Put names to the big global array\n",
        "    namesRGB = namesRGB + actualRGB\n",
        "  \n",
        "  # Open source pickle what contains data from previous tasks\n",
        "  file = open(path_of_source_pickle,'rb')\n",
        "  ourPrediction = pickle.load(file)\n",
        "  \n",
        "  # Loop throught all images\n",
        "  for photoIndex in range(len(namesRGB)):\n",
        "    # Get the name of the actual RGB picture\n",
        "    actualPic = namesRGB[photoIndex]\n",
        "    rgbPicture = cv2.imread(actualPic, 0)\n",
        "\n",
        "    for actObject in ourPrediction[actualPic][\"objects\"]:\n",
        "      # Get center coordinates of the object's bounding box\n",
        "      u = actObject[0]\n",
        "      v = actObject[1]\n",
        "      w = actObject[2]\n",
        "      h = actObject[3]\n",
        "      c = actObject[4]\n",
        "      \n",
        "      #if Class  name== 'traffic sign'\n",
        "      if c==0:\n",
        "        a = int(v-w//2)\n",
        "        b = int(v+w//2)\n",
        "        c = int(u-h//2)\n",
        "        d = int(u+h//2)\n",
        "        crop_image = rgbPicture[a:b, c:d]\n",
        "        rs_img=cv2.resize(crop_image, (32,32), interpolation = cv2.INTER_AREA)\n",
        "        rs_img_rgb= cv2.cvtColor(rs_img,cv2.COLOR_BGR2RGB)\n",
        "        dl_img = transform(rs_img_rgb)  # Preprocess image\n",
        "        dl_img = dl_img.unsqueeze(0)  # Add batch dimension\n",
        "        if haveCuda:\n",
        "          dl_img=dl_img.cuda()\n",
        "        output = model(dl_img)  # Forward pass\n",
        "        _, pred = torch.max(output, 0)  # Get predicted class\n",
        "        \n",
        "        #Put subclassName to our prediction\n",
        "        actObject[5] = pred.item()\n",
        "  \n",
        "  # Save results to our predictions\n",
        "  pickle.dump(ourPrediction, open(path_of_destination_pickle, 'wb'))\n",
        "\n",
        "\n",
        "#5 Task 3: (3d vision)\n",
        "# BASIC: 3D Vision: Determine the 3D positions of the object of interest relative to the camera. Use the center of an object's bounding box to determine the position on the image.\n",
        "# OUTPUT: x,y and z coordinates (m) of objects / pictures\n",
        "import os\n",
        "import glob\n",
        "import re\n",
        "import pickle\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "%matplotlib inline\n",
        "\n",
        "def prepend(list, str): \n",
        "    list = [str + i for i in list] \n",
        "    return(list) \n",
        "\n",
        "def sorted_nicely( l ):\n",
        "    \"\"\" Sort the given iterable in the way that humans expect.\"\"\"\n",
        "    convert = lambda text: int(text) if text.isdigit() else text\n",
        "    alphanum_key = lambda key: [ convert(c) for c in re.split('([0-9]+)', key) ]\n",
        "    return sorted(l, key = alphanum_key)\n",
        "\n",
        "def calculate_distance_2d(x1, y1, x2, y2):\n",
        "    return np.sqrt(np.square(x2-x1)+np.square(y2-y1))\n",
        "\n",
        "#TEST ARGUMENTS\n",
        "# Source: 'HW/annotations.pickle'\n",
        "# Destionation: \"HW/ourpredictions.pickle\"\n",
        "def hf_3d_task_1(path_of_source_pickle, path_of_destination_pickle):\n",
        "  # Define used arrays and variables\n",
        "  namesRGB = []\n",
        "  namesDEPTH = []\n",
        "  \n",
        "  # Set up random seed for BLUR\n",
        "  cv2.setRNGSeed(112)\n",
        "\n",
        "  # Get folders\n",
        "  myFolderList = sorted([f.path for f in os.scandir(\"/content/HW\") if f.is_dir()])\n",
        "\n",
        "  # Put all RGB and DEPTH images to an array from \"gx\" folders\n",
        "  for element in myFolderList:\n",
        "    \n",
        "    # Get and sort list of objects\n",
        "    actualRGB = (sorted_nicely(glob.glob1(element + \"/rgb\", \"*.jpg\")))\n",
        "    actualDEPTH = (sorted_nicely(glob.glob1(element + \"/depth\", \"*.png\")))\n",
        "    \n",
        "    # Add path to all images\n",
        "    path = element.replace('/content/', '')\n",
        "    actualRGB = prepend(actualRGB, path + '/rgb/')\n",
        "    actualDEPTH = prepend(actualDEPTH, path + '/depth/')\n",
        "    \n",
        "    # Put names to the big global array\n",
        "    namesRGB = namesRGB + actualRGB\n",
        "    namesDEPTH = namesDEPTH + actualDEPTH\n",
        "\n",
        "  # DIRTY MODE ON\n",
        "  # Fix yaml... :'( -> except the !dtEmptpy function throw error...\n",
        "  with open('/content/HW/calibration.yaml', 'r') as in_file:\n",
        "      buf = in_file.readlines()\n",
        "  with open('/content/HW/calibration_fixed.yaml', 'w') as out_file:\n",
        "      for line in buf:\n",
        "          if line == \"   cols: 3\\n\":\n",
        "              line = line + \"   dt: d\\n\"\n",
        "          if line == \"   cols: 5\\n\":\n",
        "              line = line + \"   dt: d\\n\"\n",
        "          out_file.write(line)\n",
        "  #  DIRTY MODE OFF\n",
        "\n",
        "  # Read calibration data\n",
        "  fs = cv2.FileStorage('/content/HW/calibration_fixed.yaml', cv2.FILE_STORAGE_READ)\n",
        "\n",
        "  # Process important nodes from calibration data\n",
        "  cameraMatrix = fs.getNode(\"camera_matrix\").mat()\n",
        "  distorsionCoefs = fs.getNode(\"distortion_coefficients\").mat()\n",
        "  distorsionModel = fs.getNode(\"distortion_model\").string()\n",
        "  picWidth = int(fs.getNode(\"image_width\").real())\n",
        "  picHeight = int(fs.getNode(\"image_height\").real())\n",
        "\n",
        "  # Open source pickle what contains data from previous tasks\n",
        "  file = open(path_of_source_pickle,'rb')\n",
        "  ourPrediction = pickle.load(file)\n",
        "\n",
        "  # Decompose camera matrix to get focal lengths expressed in pixel units and principal point\n",
        "  fx = cameraMatrix[0,0]\n",
        "  fy = cameraMatrix[1,1]\n",
        "  cx = cameraMatrix[0,2]\n",
        "  cy = cameraMatrix[1,2]\n",
        "\n",
        "  # BAISC TASK\n",
        "  # Loop throught all images\n",
        "  for photoIndex in range(len(namesRGB)):\n",
        "    # Read DEPTH map of the actual image\n",
        "    depthRaw = cv2.imread(namesDEPTH[photoIndex], -1)\n",
        "\n",
        "    # Add some BLUR\n",
        "    depth = cv2.medianBlur(depthRaw, 3)\n",
        "\n",
        "    # Convert depth map to np.float32\n",
        "    depth = np.float32(depth)\n",
        "\n",
        "    # Get the name of the actual RGB picture\n",
        "    actualPic = namesRGB[photoIndex]\n",
        "\n",
        "    # Calculate world coordinates for all objects\n",
        "    for actObject in ourPrediction[actualPic][\"objects\"]:\n",
        "      # Get center coordinates of the object's bounding box\n",
        "      u = actObject[0]\n",
        "      v = actObject[1]\n",
        "\n",
        "      # Convert 2D points to 3D space (and get values in METERs)\n",
        "      ourX = ((depth[v, u] / fx) * (u - cx)) / 1000\n",
        "      ourY = ((-1)*(depth[v, u] / fy) * (v - cy))/1000\n",
        "      ourZ = depth[v, u]/1000\n",
        "\n",
        "      # Put 3D coordinates to our prediction (fill space in list or append, if space not exists)\n",
        "      if len(actObject) < 7:\n",
        "        actObject.append(ourX)\n",
        "      else:\n",
        "        actObject[6] = ourX\n",
        "      if len(actObject) < 8:\n",
        "        actObject.append(ourY)\n",
        "      else:\n",
        "        actObject[7] = ourY\n",
        "      if len(actObject) < 9:\n",
        "        actObject.append(ourZ)\n",
        "      else:\n",
        "        actObject[8] = ourZ\n",
        "\n",
        "  # Save results to our predictions\n",
        "  pickle.dump(ourPrediction, open(path_of_destination_pickle, 'wb'))\n",
        "  \n",
        "  # Load results to another isntance\n",
        "  file = open(path_of_destination_pickle,'rb')\n",
        "  ourHCPredictions = pickle.load(file)\n",
        "  \n",
        "  # HARDCORE TASK\n",
        "  \n",
        "  # Define the scannable part (half)size and define mats\n",
        "  rangeOfScan = 33\n",
        "  # 3D points of the actual picture\n",
        "  obj = np.arange(rangeOfScan*rangeOfScan*3, dtype='float32').reshape(rangeOfScan*rangeOfScan,3,1)\n",
        "  # 2D points of the previous picture\n",
        "  img = np.arange(rangeOfScan*rangeOfScan*2, dtype='float32').reshape(rangeOfScan*rangeOfScan,2,1)\n",
        "  \n",
        "  # Copy ourHCPrediction (to keep it clean)\n",
        "  copyOfPred = ourHCPredictions\n",
        "\n",
        "  # Loop throught all images\n",
        "  for actPic in namesRGB:\n",
        "    # Initialize INVALID minimum parameters to the minimum search\n",
        "    minimumVal = 10000\n",
        "    minimumIdx = 0\n",
        "\n",
        "    # Calculate all element's distance from center and choose the nearest\n",
        "    for actObject in copyOfPred[actPic][\"objects\"]:\n",
        "      # Get center coordinatees\n",
        "      actU = actObject[0]\n",
        "      actV = actObject[1]\n",
        "\n",
        "      # Measure distance from center\n",
        "      distanceFromCenter = calculate_distance_2d(actU, actV, 320, 240)\n",
        "\n",
        "      # Minimum search\n",
        "      if (minimumVal > distanceFromCenter):\n",
        "        minimumVal = distanceFromCenter\n",
        "        minimumIdx = copyOfPred[actPic][\"objects\"].index(actObject)\n",
        "      \n",
        "      # Save minimum index to the dictionary\n",
        "      copyOfPred[actPic][\"minidx\"] = minimumIdx\n",
        "\n",
        "  # Loop throught all images\n",
        "  for photoIndex in range(len(namesRGB)):\n",
        "    # Get ACTUAL picture name\n",
        "    actualPic = namesRGB[photoIndex]\n",
        "    \n",
        "    # Run if we have pictures from the same video\n",
        "    if (\"/1.jpg\" not in actualPic):\n",
        "      # Get PREVIOUS picture name and ACTUAL depth map\n",
        "      prevPic = namesRGB[photoIndex - 1]\n",
        "      prevPicDepth = namesDEPTH[photoIndex - 1]\n",
        "      \n",
        "      # Get the index of the nearest object from the center\n",
        "      minIdxAct = copyOfPred[actualPic][\"minidx\"]\n",
        "      minIdxPrev = copyOfPred[prevPic][\"minidx\"]\n",
        "      \n",
        "      # Measure range of scan from center of the ACTUAL picture and add the left bottom corner point\n",
        "      limitLeft = copyOfPred[actualPic][\"objects\"][minIdxAct][1] - int((rangeOfScan-1)/2) \n",
        "      limitBottom = copyOfPred[actualPic][\"objects\"][minIdxAct][0] - int((rangeOfScan-1)/2) \n",
        "\n",
        "      # Load depth map and do same conditioning as before \n",
        "      depthRaw = cv2.imread(prevPicDepth, -1)\n",
        "      depth = cv2.medianBlur(depthRaw, 3)\n",
        "      depth = np.float32(depth)\n",
        "      \n",
        "      # Convert 2D coordinates to 3D space in the scanned RANGE and save in ACTUAL PICTURE\n",
        "      indexOfScannedRange = 0\n",
        "      for u in range(limitLeft, limitLeft + rangeOfScan):\n",
        "        for v in range(limitBottom, limitBottom + rangeOfScan):\n",
        "          obj[indexOfScannedRange][0] = ((depth[v, u] / fx) * (u - cx)) / 1000\n",
        "          obj[indexOfScannedRange][1] = ((-1)*(depth[v, u] / fy) * (v - cy))/1000\n",
        "          obj[indexOfScannedRange][2] = depth[v, u]/1000\n",
        "          indexOfScannedRange += 1\n",
        "      \n",
        "      # Try to find a pair to this object or use the nearest from the center in PREVIUOS picture\n",
        "      counterObj = 0\n",
        "      for prevObj in copyOfPred[prevPic][\"objects\"]:\n",
        "        # Get comparable types of the objects\n",
        "        actType = copyOfPred[actualPic][\"objects\"][minIdxAct][4]\n",
        "        actSubType = copyOfPred[actualPic][\"objects\"][minIdxAct][5]\n",
        "        prevType = prevObj[4]\n",
        "        prevSubType = prevObj[5]\n",
        "\n",
        "        # Change nearest object to the similar if possible\n",
        "        if actType == prevType and actSubType == prevSubType:\n",
        "          minIdxPrev = counterObj\n",
        "        counterObj += 1\n",
        "\n",
        "      # Measure range of scan from center of the PREVIOUS picture and add the left bottom corner point\n",
        "      limitLeft = copyOfPred[prevPic][\"objects\"][minIdxPrev][1] - int((rangeOfScan-1)/2)\n",
        "      limitBottom = copyOfPred[prevPic][\"objects\"][minIdxPrev][0] - int((rangeOfScan-1)/2)\n",
        "\n",
        "      # Save 2D coordinates in ACTUAL PICTURE\n",
        "      indexOfScannedRange = 0\n",
        "      for u in range(limitLeft, limitLeft + rangeOfScan):\n",
        "        for v in range(limitBottom, limitBottom + rangeOfScan):\n",
        "          img[indexOfScannedRange][0] = u\n",
        "          img[indexOfScannedRange][1] = v\n",
        "          indexOfScannedRange += 1\n",
        "      \n",
        "      # Put 3D and 2D pairs to the PnP problem solver ang get rotation vector and translation mat\n",
        "      returnVal, rotVector, translationMat = cv2.solvePnP(obj, img, cameraMatrix, distorsionCoefs, flags=cv2.SOLVEPNP_ITERATIVE) \n",
        "\n",
        "      # PNP solved\n",
        "      if returnVal == True:\n",
        "        # Calculate rotation with Rodrigues formula\n",
        "        rotMat = cv2.Rodrigues(rotVector)[0]\n",
        "        \n",
        "        # Assemble pose mat\n",
        "        poseMat = np.hstack((-rotMat.T,translationMat))\n",
        "\n",
        "        # Save relative to the previous pose\n",
        "        ourHCPredictions[actualPic][\"poses\"] = np.abs(poseMat.reshape(12))*ourHCPredictions[prevPic][\"poses\"]\n",
        "\n",
        "      # PNP error -> Put identity mat to the prediction\n",
        "      else:\n",
        "        ourHCPredictions[actualPic][\"poses\"] = np.hstack((np.eye(3),np.zeros(3).reshape(3, 1))).reshape(12)\n",
        "  \n",
        "  # Save dictionary\n",
        "  pickle.dump(ourHCPredictions, open(path_of_destination_pickle, 'wb'))   \n",
        "\n",
        "# Call Task3 function\n",
        "# hf_3d_task_1('HW/annotations.pickle', \"HW/ourpredictions.pickle\")\n",
        "#hf_3d_task_1('HW/ourpredictions.pickle', \"HW/ourpredictions.pickle\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pSRADdkYd0Er",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        },
        "outputId": "94dd2a76-5c70-4b84-adf2-63a40a8b1f19"
      },
      "source": [
        "from HW.evaluate import evaluate\n",
        "\n",
        "# Task 1\n",
        "#myAnswers = createMyAnswers()\n",
        "#pickle.dump(myAnswers, open('HW/ourpredictions.pickle', 'wb'))\n",
        "\n",
        "#Task 2\n",
        "hf_DL_task('HW/ourpredictions.pickle',\"HW/ourpredictions.pickle\")\n",
        "\n",
        "# Task 3\n",
        "hf_3d_task_1('HW/ourpredictions.pickle', \"HW/ourpredictions.pickle\")\n",
        "\n",
        "file = open('HW/ourpredictions.pickle','rb')\n",
        "pre = pickle.load(file)\n",
        "\n",
        "evaluate(pre)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Task 1: 0.8220929370784851\n",
            "Task 1 HC: 0.5140449438202247\n",
            "Task 2: 0.7182539682539683\n",
            "Task 2 HC: 1.0\n",
            "Task 3: 0.9322575719646632\n",
            "Task 3 HC: 0.6065633637405526\n",
            "Total:  4.5932127848578945\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}